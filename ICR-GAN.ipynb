{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5b3fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23fa4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory for dataset\n",
    "dataroot = \"/Volumes/gordonssd/cifar10\"\n",
    "# Directory to output images and model checkpoints\n",
    "outf = \"/Users/soymilk/Desktop/icr-gan/output\"\n",
    "# Number of workers for dataloader\n",
    "workers = 2\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "# Spatial size of training images. All images will be resized to this\n",
    "#   size using a transformer.\n",
    "image_size = 32\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 3\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 100\n",
    "# Size of feature maps in generator\n",
    "ngf = 64\n",
    "# Size of feature maps in discriminator\n",
    "ndf = 64\n",
    "# Number of training epochs\n",
    "num_epochs = 5\n",
    "# Learning rate for optimizers\n",
    "lr = 0.0002\n",
    "# Beta1 hyperparam for Adam optimizers\n",
    "beta1 = 0.5\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 0\n",
    "# Consistency regularization for real and fake images (bCR)\n",
    "lambda_real = 10 \n",
    "lambda_fake = 10\n",
    "# Consistency regularization for discriminator and generator (zCR)\n",
    "lambda_dis = 5\n",
    "lambda_gen = 0.5\n",
    "# Latent transform noise\n",
    "sigma_noise = 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a50924",
   "metadata": {},
   "source": [
    "<h3>Load CIFAR10</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4573b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = dset.CIFAR10(root=dataroot, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize(image_size),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                       ]))\n",
    "nc=3\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c8834",
   "metadata": {},
   "source": [
    "<h3>Initialise pre-trained DCGAN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b50af151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the models\n",
    "from dcgan import Discriminator, Generator\n",
    "\n",
    "netD = Discriminator(ngpu)\n",
    "netG = Generator(ngpu)\n",
    "\n",
    "# load weights\n",
    "netD.load_state_dict(torch.load('weights/netD_epoch_4.pth', map_location=torch.device('cpu')))\n",
    "netG.load_state_dict(torch.load('weights/netG_epoch_4.pth', map_location=torch.device('cpu')))\n",
    "if torch.cuda.is_available():\n",
    "    netD = netD.cuda()\n",
    "    netG = netG.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38c49ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52fac32",
   "metadata": {},
   "source": [
    "<h3>Loss function and Optimizers</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ed1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "l2loss = nn.MSELoss()\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50209be",
   "metadata": {},
   "source": [
    "<h3>Augmentations</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7db21b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.RandomRotation(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99f92b",
   "metadata": {},
   "source": [
    "<h2>Train Balanced Consistency Regularization DCGAN (bCR-DCGAN)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1d1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        x = data[0].to(device)\n",
    "        \n",
    "        # bCR: Augment real images\n",
    "        T_x = transform(x)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "        D_x = netD(x)\n",
    "        \n",
    "        # bCR: Forward pass augmented real batch through D\n",
    "        D_T_x = netD(T_x) \n",
    "        \n",
    "        errD_real = criterion(D_x, label)\n",
    "\n",
    "        # bCR: Calculate L_real: |D(x) − D(T(x))|^2 \n",
    "        L_real = l2loss(D_x, D_T_x)\n",
    "        \n",
    "        (errD_real + lambda_real*L_real).backward()\n",
    "        \n",
    "        D_x = D_x.mean().item()\n",
    "        \n",
    "        # train with fake\n",
    "        z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        G_z = netG(z)\n",
    "        \n",
    "        # bCR: Augment generated images\n",
    "        T_G_z = transform(G_z.detach())\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        D_G_z = netD(G_z.detach())\n",
    "        \n",
    "        # bCR: Forward pass augmented fake batch through D\n",
    "        D_T_G_z = netD(T_G_z)\n",
    "        \n",
    "        errD_fake = criterion(D_G_z, label)\n",
    "        \n",
    "        # bCR: Calculate L_fake: |D(G(z)) − D(T(G(z)))|^2\n",
    "        L_fake = l2loss(D_G_z, D_T_G_z)\n",
    "        \n",
    "        (errD_fake + lambda_fake*L_fake).backward()\n",
    "        \n",
    "        D_G_z1 = D_G_z.mean().item()\n",
    "        L_D = errD_real + errD_fake\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        D_G_z = netD(G_z)\n",
    "        errG = criterion(D_G_z, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = D_G_z.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_real: %.4f Loss_fake: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, num_epochs, i, len(dataloader),\n",
    "                 L_D.item(), L_real.item(), L_fake.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(x,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f249f",
   "metadata": {},
   "source": [
    "<h2>Train Latent Consistency Regularization DCGAN (zCR-DCGAN)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488babe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        x = data[0].to(device)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        D_x = netD(x)\n",
    "        errD_real = criterion(D_x, label)\n",
    "        errD_real.backward()\n",
    "        D_x = D_x.mean().item()\n",
    "        \n",
    "        # train with fake\n",
    "        z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        \n",
    "        # zCR: transform z\n",
    "        T_z = z + torch.normal(0, sigma_noise, z.shape)\n",
    "        \n",
    "        G_z = netG(z)\n",
    "        \n",
    "        # zCR: Forward pass T_z through G\n",
    "        G_T_z = netG(T_z)\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        D_G_z = netD(G_z.detach())\n",
    "        errD_fake = criterion(D_G_z, label)\n",
    "        \n",
    "        # zCR: Forward pass G_T_z through G\n",
    "        D_G_T_z = netD(G_T_z.detach())\n",
    "        # zCR: Calculate L_dis |D(G(z)) − D(G(T(z))|^2\n",
    "        L_dis = l2loss(D_G_z, D_G_T_z)\n",
    "        \n",
    "        (errD_fake + lambda_dis*L_dis).backward() \n",
    "        \n",
    "        D_G_z1 = D_G_z.mean().item()\n",
    "        L_D = errD_real + errD_fake\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        D_G_z = netD(G_z)\n",
    "        errG = criterion(D_G_z, label)\n",
    "        \n",
    "        D_G_T_z = netD(G_T_z)\n",
    "        # zCR_TODO: Calculate L_gen −|G(z) − G(T(z)|^2 \n",
    "        L_gen = -l2loss(G_z, G_T_z)\n",
    "        \n",
    "        (errG + lambda_gen*L_gen).backward()\n",
    "        \n",
    "        D_G_z2 = D_G_z.mean().item()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_dis: %.4f Loss_G: %.4f Loss_gen: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "                      % (epoch, num_epochs, i, len(dataloader),\n",
    "                         L_D.item(), L_dis.item(), errG.item(), L_gen.item(), D_x, D_G_z1, D_G_z2))\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(x,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7776f702",
   "metadata": {},
   "source": [
    "<h2>Train Improved Consistency Regularization DCGAN (ICR-DCGAN) bCR+zCR</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # Train with all-real batch\n",
    "        netD.zero_grad()\n",
    "        x = data[0].to(device)\n",
    "        \n",
    "        # bCR: Augment real images\n",
    "        T_x = transform(x)\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        D_x = netD(x)\n",
    "        \n",
    "        # bCR: Forward pass augmented real batch through D\n",
    "        D_T_x = netD(T_x) \n",
    "        \n",
    "        errD_real = criterion(D_x, label)\n",
    "        # bCR: Calculate L_real: |D(x) − D(T(x))|^2 \n",
    "        L_real = l2loss(D_x, D_T_x)\n",
    "        \n",
    "        (errD_real + lambda_real*L_real).backward()\n",
    "        \n",
    "        D_x = D_x.mean().item()\n",
    "        \n",
    "        # train with fake\n",
    "        z = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        \n",
    "        # zCR: transform z\n",
    "        T_z = z + torch.normal(0,1,z.shape)\n",
    "        \n",
    "        G_z = netG(z)\n",
    "        \n",
    "        # bCR: Augment generated images\n",
    "        T_G_z = transform(G_z.detach())\n",
    "        \n",
    "        # zCR: Forward pass T_z through G\n",
    "        G_T_z = netG(T_z)\n",
    "        \n",
    "        label.fill_(fake_label)\n",
    "        D_G_z = netD(G_z.detach())\n",
    "        \n",
    "        # bCR: Forward pass augmented fake batch through D\n",
    "        D_T_G_z = netD(T_G_z)\n",
    "        \n",
    "        errD_fake = criterion(D_G_z, label)\n",
    "        \n",
    "        # bCR: Calculate L_fake: |D(G(z)) − D(T(G(z)))|^2\n",
    "        L_fake = l2loss(D_G_z, D_T_G_z)\n",
    "        \n",
    "        # zCR: Forward pass G_T_z through G\n",
    "        D_G_T_z = netD(G_T_z.detach())\n",
    "        # zCR: Calculate L_dis |D(G(z)) − D(G(T(z))|^2\n",
    "        L_dis = l2loss(D_G_z, D_G_T_z)\n",
    "        \n",
    "        (errD_fake + lambda_dis*L_dis + lambda_fake*L_fake).backward() \n",
    "        \n",
    "        D_G_z1 = D_G_z.mean().item()\n",
    "        L_D = errD_real + errD_fake\n",
    "        \n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # fake labels are real for generator cost\n",
    "        D_G_z = netD(G_z)\n",
    "        errG = criterion(D_G_z, label)\n",
    "        \n",
    "        D_G_T_z = netD(G_T_z)\n",
    "        # zCR_TODO: Calculate L_gen −|G(z) − G(T(z)|^2 \n",
    "        L_gen = -l2loss(G_z, G_T_z)\n",
    "        \n",
    "        (errG + lambda_gen*L_gen).backward()\n",
    "        \n",
    "        D_G_z2 = D_G_z.mean().item()\n",
    "        optimizerG.step()\n",
    "\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            \n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_real: %.4f Loss_fake: %.4f Loss_dis: %.4f Loss_G: %.4f Loss_gen: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, num_epochs, i, len(dataloader),\n",
    "                 L_D.item(), L_real.item(), L_fake.item(), L_dis.item(), errG.item(), L_gen.item(), D_x, D_G_z1, D_G_z2))\n",
    "            \n",
    "            vutils.save_image(x,\n",
    "                    '%s/real_samples.png' % outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (outf, epoch),\n",
    "                    normalize=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (outf, epoch))\n",
    "    torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (outf, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8d609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
